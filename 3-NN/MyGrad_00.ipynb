{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mygrad as mg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sigmoid():\n",
    "    @staticmethod\n",
    "    def activation(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    @staticmethod\n",
    "    def prime(y):\n",
    "        f = sigmoid.activation(y)\n",
    "        return (f * (1 - f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmax:\n",
    "    @staticmethod\n",
    "    def activation(x):\n",
    "        # e_x = np.exp(x).reshape(-1,1)\n",
    "        e_x = np.exp(x - np.max(x,axis=-1).reshape(-1,1))\n",
    "        return e_x / e_x.sum(axis=-1).reshape(-1,1)\n",
    "    @staticmethod\n",
    "    def primeP(y): #marche pas\n",
    "        n = y.shape[1]\n",
    "        print(n,y.shape)\n",
    "        i = np.identity(n)\n",
    "        un = np.ones((n,y.shape[1]))\n",
    "        SM = y.reshape((-1,1))\n",
    "        print(SM.shape)\n",
    "        jac = np.diagflat(y) - np.dot(SM, SM.T)\n",
    "        j = np.dot((i* jac),un)\n",
    "        # x = np.dot(jac,y.T)\n",
    "        return j.T\n",
    "    @staticmethod\n",
    "    def prime(y):\n",
    "        return(y * (1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropy:\n",
    "    def __init__(self, p, y,_m):\n",
    "        self.p = p\n",
    "        self.y = y\n",
    "        self.m = _m\n",
    "    def metrics(self):\n",
    "        m = self.p.shape[0]\n",
    "        return (-1 / m) * (np.sum((self.y * np.log(self.p + 1e-8)) + ((1 - self.y) * (np.log(1 - self.p + 1e-8)))))\n",
    "\n",
    "    def forward(self):\n",
    "    # -(y.log(p) + (1-y).log(1-p))\n",
    "        return (-self.y * np.log(self.p + 1e-8)) + ((1 - self.y) * (np.log(1 - self.p + 1e-8)))\n",
    "\n",
    "    def backward(self):\n",
    "    # -(y/p + (1-y)/(1-p))\n",
    "        return (-self.y/(self.p+1e-8) + (1 - self.y)/(1 - self.p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30830853 0.17855733 0.51313414]\n",
      " [0.24060612 0.66078529 0.0986086 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.69169147,  0.17855733,  0.51313414],\n",
       "       [ 0.24060612, -0.33921471,  0.0986086 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(128)\n",
    "x = np.random.randn(2,2)\n",
    "y = np.array([[1,0,0],[0,1,0]])\n",
    "w = np.random.randn(2,3)\n",
    "b = np.zeros((3))\n",
    "z = np.dot(x,w) + b\n",
    "a = softmax.activation(z)\n",
    "# a = sigmoid.activation(z)\n",
    "print(a)\n",
    "dL = a - y\n",
    "dL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.17665425, -0.19669312, -0.71976661],\n",
       "       [-0.27523467,  0.41432631, -0.10381569]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LossFct = BinaryCrossEntropy(a,y,0)\n",
    "L = LossFct.forward()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.24350407,  1.21737042,  2.05395382],\n",
       "       [ 1.31683969, -1.51335087,  1.10939598]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dL = LossFct.backward()\n",
    "dL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21325438 0.14667461 0.24982749]\n",
      " [0.18271481 0.22414809 0.08888494]]\n"
     ]
    }
   ],
   "source": [
    "# da_dz = sigmoid.prime(a)\n",
    "# da_dz = softmax.prime(a)\n",
    "da_dz = softmax.prime(a)\n",
    "\n",
    "print(da_dz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69169147  0.17855733  0.51313414]\n",
      " [ 0.24060612 -0.33921471  0.0986086 ]]\n",
      "[[ 1.17665425 -0.19669312 -0.71976661]\n",
      " [-0.27523467  0.41432631 -0.10381569]]\n",
      "[[-3.24350407  1.21737042  2.05395382]\n",
      " [ 1.31683969 -1.51335087  1.10939598]]\n",
      "[[0.21325438 0.14667461 0.24982749]\n",
      " [0.18271481 0.22414809 0.08888494]]\n",
      "[[-0.69169145  0.17855733  0.51313414]\n",
      " [ 0.24060612 -0.33921471  0.0986086 ]]\n"
     ]
    }
   ],
   "source": [
    "print(a-y)\n",
    "print(L)\n",
    "print(dL)\n",
    "print(da_dz)\n",
    "print((dL*da_dz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.20786097 -0.23538131 -1.23783058]\n",
      " [-0.3509888   0.24266002 -0.11459339]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (2,3) and (2,3) not aligned: 3 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb Cellule 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dL \u001b[39m=\u001b[39m LossFct\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(softmax\u001b[39m.\u001b[39mprime(L))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dL_da \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(dL,softmax\u001b[39m.\u001b[39;49mprime(L))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dL_da\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,3) and (2,3) not aligned: 3 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "dL = LossFct.backward()\n",
    "print(softmax.prime(L))\n",
    "dL_da = np.dot(dL,softmax.prime(L))\n",
    "dL_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb Cellule 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m i \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39midentity(\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m un \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m j \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot((i\u001b[39m*\u001b[39;49m da_dz),un)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rky/Documents/GitHub/Machine-Learning/3-NN/MyGrad_00.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m j\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3) (2,3) "
     ]
    }
   ],
   "source": [
    "i = np.identity(3)\n",
    "un = np.ones((3,1))\n",
    "j = np.dot((i* da_dz),un)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "game_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc6c2409e22df4b6dc6c42eb7addfe820be784db604d44dacc946a75b91b0504"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
